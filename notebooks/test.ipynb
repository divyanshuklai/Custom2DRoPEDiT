{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48daa446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import PIL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d205499",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(torch.accelerator.current_accelerator() if torch.accelerator.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"./data\", train=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape, labels.shape)\n",
    "grid = torchvision.utils.make_grid(images, nrow=16)\n",
    "grid = grid.permute(1,2,0)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa80344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.engine.trainer import RectifiedFlowTrainer\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import wandb\n",
    "from torchinfo import summary\n",
    "from src.models.rope_dit_modelling import RoPEDiT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4bd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(trainer, train_loader, num_iter, device, run=None):\n",
    "    trainer.model.to(device)\n",
    "    trainer.model.train()\n",
    "\n",
    "    data_iter = itertools.cycle(train_loader)\n",
    "\n",
    "    progress_bar = tqdm(range(1, num_iter+1))\n",
    "    for step in progress_bar:\n",
    "\n",
    "        images, labels = next(data_iter)\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        loss = trainer.step(images, labels)\n",
    "\n",
    "        if step%100==0 and (run is not None):\n",
    "            run.log({\n",
    "                \"loss\":loss,\n",
    "                \"step\":step\n",
    "            })\n",
    "\n",
    "        if num_iter > 10 and step%(num_iter//10) == 0:\n",
    "            trainer.model.eval()\n",
    "            torch.save(trainer.model.state_dict(), f\"trained/checkpoints/{run.name}_step_{step}_loss_{loss:.4f}.pt\")\n",
    "            trainer.model.train()\n",
    "\n",
    "        progress_bar.set_description(f\"step : {step} | loss : {loss}\")\n",
    "\n",
    "    trainer.model.eval()\n",
    "    \n",
    "    if run is not None:\n",
    "        torch.save(trainer.model.state_dict(), f\"trained/{run.name}_final.pt\")\n",
    "        run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ hyperparameters #############\n",
    "\n",
    "model_config = dict(model_dim=256,\n",
    "                    num_dit_blocks=6,\n",
    "                    num_attn_heads=8,\n",
    "                    patch_size=4,\n",
    "                    num_classes=len(train_set.classes),\n",
    "                    in_channels=3,\n",
    "                    use_cfg=True)\n",
    "\n",
    "learning_rate = 3e-4\n",
    "drop_prob = 0.2\n",
    "num_iterations = 5_000\n",
    "batch_size = 512\n",
    "\n",
    "##########################################\n",
    "\n",
    "DiT = RoPEDiT(**model_config)\n",
    "\n",
    "print(summary(DiT,\n",
    "        input_data=[\n",
    "            images,\n",
    "            labels,\n",
    "            torch.ones_like(labels),\n",
    "        ]))\n",
    "DiT.compile(fullgraph=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(DiT.parameters(), lr=learning_rate)\n",
    "\n",
    "trainer = RectifiedFlowTrainer(DiT, optimizer, drop_prob)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "run = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e61bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run = wandb.init(\n",
    "    project=\"customDiT\",\n",
    "    entity=\"divyanshukla\",\n",
    "    config={\n",
    "        \"model_config\":model_config,\n",
    "        \"learning_rate\":learning_rate,\n",
    "        \"drop_prob\":drop_prob,\n",
    "        \"num_iterations\":num_iterations,\n",
    "        \"data\":{\n",
    "                \"dataset\":train_set.filename,\n",
    "                \"transform\":transform,\n",
    "                \"batch_size\":batch_size,\n",
    "                },\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3250224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(trainer, train_loader, num_iterations, device, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.model.eval()\n",
    "# torch.save(trainer.model.state_dict(), f\"models/{run.name}_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fef95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load(f\"models/playful-aardvark-14_final.pt\", DiT.state_dict())\n",
    "# DiT.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433fde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils.sampler as sampler\n",
    "from src.utils.sampler import euler_sampler\n",
    "\n",
    "num_samples = 4\n",
    "\n",
    "x0 = torch.randn((num_samples, *images.shape[1:]), device=device)\n",
    "y = torch.randint(len(train_set.classes), size=(num_samples,), device=device)\n",
    "h = 1e-2\n",
    "num_steps = int(1/h)\n",
    "cfg_scale = 4.0\n",
    "\n",
    "x = euler_sampler(DiT, x0, y, h, num_steps, with_traj=False, cfg_scale=cfg_scale).cpu()\n",
    "\n",
    "mean = torch.tensor((0.4914, 0.4822, 0.4465)).view(1, -1, 1, 1) \n",
    "std = torch.tensor((0.247, 0.243, 0.261)).view(1, -1, 1, 1)\n",
    "\n",
    "x = x*std + mean\n",
    "\n",
    "grid = torchvision.utils.make_grid(x, nrow=(num_samples//2))\n",
    "grid = grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_set.classes[i] for i in list(y.cpu()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_transformer (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
